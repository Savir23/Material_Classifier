{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af81dcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal imports needed for fetching and processing (no local audio dir, handle .m4a)\n",
    "import os\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "from urllib.parse import unquote\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import librosa\n",
    "from dotenv import load_dotenv\n",
    "from supabase import create_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10842576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57471e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\savir\\MaterialClassifier\\src\n",
      "Files Here: ['.env', 'audio', 'audio_processing.py', 'models', 'train_model.ipynb', '_init_.py']\n",
      "Looking for .env at: c:\\Users\\savir\\MaterialClassifier\\src\\.env\n",
      "URL: https://lapffcqqdubcyswirkye.supabase.co\n",
      "KEY length: 208\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"Files Here:\", os.listdir())\n",
    "notebook_folder = os.path.dirname(os.path.abspath(\"__file__\"))  # safer for scripts\n",
    "dotenv_path = os.path.join(notebook_folder, \".env\")\n",
    "\n",
    "print(\"Looking for .env at:\", dotenv_path)\n",
    "\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "SUPABASE_URL = os.getenv(\"SUPABASE_URL\")\n",
    "SUPABASE_KEY = os.getenv(\"SUPABASE_KEY\")\n",
    "\n",
    "print(\"URL:\", SUPABASE_URL)\n",
    "print(\"KEY length:\", len(SUPABASE_KEY) if SUPABASE_KEY else \"None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caaeed51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fetched successfully\n",
      "                                     id  \\\n",
      "0  6fcad7a6-a3eb-4ef1-bb30-36af8effa53a   \n",
      "\n",
      "                                           file_name  \\\n",
      "0  Paper_Large_10in_Flat_Cardboard_2025-10-31T02-...   \n",
      "\n",
      "                                            file_url description material  \\\n",
      "0  https://lapffcqqdubcyswirkye.supabase.co/stora...   Cardboard    Paper   \n",
      "\n",
      "            size shape                      timestamp  \\\n",
      "0  Large (>10in)  Flat  2025-10-31T02:07:43.551+00:00   \n",
      "\n",
      "                        created_at  \\\n",
      "0  2025-10-31T02:07:43.78475+00:00   \n",
      "\n",
      "                                   ambient_file_name  ambient_duration_ms  \n",
      "0  Paper_Large_10in_Flat_Cardboard_2025-10-31T02-...                 1500  \n"
     ]
    }
   ],
   "source": [
    "supabase = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
    "table_name = \"recordings_metadata\"\n",
    "response  = supabase.table(table_name).select(\"*\").execute()\n",
    "if response.data:\n",
    "    df = pd.DataFrame(response.data)\n",
    "    print(\"Data fetched successfully\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"No data found in the table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eaabd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 1; Columns: ['id', 'file_name', 'file_url', 'description', 'material', 'size', 'shape', 'timestamp', 'created_at', 'ambient_file_name', 'ambient_duration_ms']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Rows: {len(df)}; Columns: {list(df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2032969",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMBIENT_DURATION_SEC = 1.5\n",
    "\n",
    "def split_ambient_chirp(audio_array, sample_rate):\n",
    "    data = audio_array\n",
    "    sr = sample_rate\n",
    "    if data.ndim > 1:\n",
    "        data = data[:, 0]\n",
    "    split_sample = int(sr * AMBIENT_DURATION_SEC)\n",
    "    ambient = data[:split_sample]\n",
    "    chirp = data[split_sample:]\n",
    "    return ambient, chirp, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fd08c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_subtract(ambient, chirp):\n",
    "    fft_ambient = np.fft.fft(ambient)\n",
    "    fft_chirp = np.fft.fft(chirp)\n",
    "    subtracted = np.abs(fft_chirp) - np.abs(fft_ambient)\n",
    "    subtracted[subtracted < 0] = 0\n",
    "    return subtracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531856be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 1 rows from recordings_metadata\n",
      "❌ Failed processing Paper_Large_10in_Flat_Cardboard_2025-10-31T02-07-42_full.m4a: [Errno 13] Permission denied: 'C:\\\\Users\\\\savir\\\\AppData\\\\Local\\\\Temp\\\\tmp6of4xtxq.m4a'\n",
      "No recordings processed. Check storage keys (file_name) and that ffmpeg is available for m4a decoding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\savir\\AppData\\Local\\Temp\\ipykernel_3040\\3171386576.py:14: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, sample_rate = librosa.load(tmp.name, sr=sr, mono=True)\n",
      "c:\\Users\\savir\\MaterialClassifier\\venv\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    }
   ],
   "source": [
    "# Process m4a files directly from Supabase without storing in audio/\n",
    "BUCKET_NAME = \"recordings\"  # change if your bucket is named differently\n",
    "\n",
    "# --- Load recordings metadata from Supabase ---\n",
    "response = supabase.table(\"recordings_metadata\").select(\"*\").execute()\n",
    "df = pd.DataFrame(response.data)\n",
    "print(f\"✅ Loaded {len(df)} rows from recordings_metadata\")\n",
    "\n",
    "# --- Helper to load m4a to numpy using a temporary file and librosa ---\n",
    "def load_m4a_from_bytes(m4a_bytes: bytes, sr: int | None = None):\n",
    "    tmp = tempfile.NamedTemporaryFile(suffix=\".m4a\", delete=False)\n",
    "    try:\n",
    "        tmp.write(m4a_bytes)\n",
    "        tmp.flush()\n",
    "        tmp_path = tmp.name\n",
    "    finally:\n",
    "        tmp.close()  # important on Windows to release the handle before reading\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(tmp_path, sr=sr, mono=True)\n",
    "    finally:\n",
    "        try:\n",
    "            os.remove(tmp_path)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return audio, sample_rate\n",
    "\n",
    "# --- Stream one example through spectral subtraction (no saving) ---\n",
    "processed = 0\n",
    "for idx, row in df.iterrows():\n",
    "    object_path = row.get(\"file_name\")\n",
    "    if not object_path:\n",
    "        continue\n",
    "    object_path = unquote(object_path)\n",
    "\n",
    "    try:\n",
    "        m4a_bytes = supabase.storage.from_(BUCKET_NAME).download(object_path)\n",
    "    except Exception as e:\n",
    "        # Fallback to signed URL\n",
    "        try:\n",
    "            signed = supabase.storage.from_(BUCKET_NAME).create_signed_url(object_path, 60)\n",
    "            signed_url = signed.get(\"signedURL\") or signed.get(\"signed_url\") or signed.get(\"url\")\n",
    "            r = requests.get(signed_url, timeout=30)\n",
    "            r.raise_for_status()\n",
    "            m4a_bytes = r.content\n",
    "        except Exception as e2:\n",
    "            print(f\"⚠️ Could not fetch {object_path}: {e2}\")\n",
    "            continue\n",
    "\n",
    "    try:\n",
    "        audio, sr = load_m4a_from_bytes(m4a_bytes, sr=None)\n",
    "        ambient, chirp, _ = split_ambient_chirp(audio, sample_rate=sr)\n",
    "        spec = spectral_subtract(ambient, chirp)\n",
    "        print(f\"✅ Spectral subtraction computed: sr={sr}, ambient={len(ambient)}, chirp={len(chirp)}, spec={len(spec)}\")\n",
    "        processed += 1\n",
    "        break  # stop after first successful example as requested\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed processing {object_path}: {e}\")\n",
    "\n",
    "if processed == 0:\n",
    "    print(\"No recordings processed. Check storage keys (file_name) and that ffmpeg is available for m4a decoding.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "418eb831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found WAV files: []\n",
      "No WAVs downloaded. Check logs above.\n"
     ]
    }
   ],
   "source": [
    "# Verify downloaded WAVs and run split + spectral subtraction on one example\n",
    "from scipy.io.wavfile import read as wavread\n",
    "\n",
    "wav_files = sorted([f for f in os.listdir(LOCAL_AUDIO_DIR) if f.lower().endswith('.wav')])\n",
    "print(\"Found WAV files:\", wav_files)\n",
    "\n",
    "if wav_files:\n",
    "    test_path = os.path.join(LOCAL_AUDIO_DIR, wav_files[0])\n",
    "    print(\"Testing:\", test_path)\n",
    "    sr, data = wavread(test_path)\n",
    "    ambient, chirp, sr2 = split_ambient_chirp(test_path)\n",
    "    spec = spectral_subtract(ambient, chirp)\n",
    "    print(f\"Sample rate: {sr}, ambient len: {len(ambient)}, chirp len: {len(chirp)}, spec len: {len(spec)}\")\n",
    "else:\n",
    "    print(\"No WAVs downloaded. Check logs above.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "989a4145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 0 samples with 512 features each\n"
     ]
    }
   ],
   "source": [
    "# Build dataset: spectral-subtraction features per recording\n",
    "from scipy.io.wavfile import read as wavread\n",
    "from urllib.parse import unquote\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "paths = []\n",
    "\n",
    "K_BINS = 512  # number of frequency bins to keep\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    object_path = row.get(\"file_name\")\n",
    "    if not object_path:\n",
    "        continue\n",
    "    object_path = unquote(object_path)\n",
    "    local_path = os.path.join(LOCAL_AUDIO_DIR, os.path.basename(object_path))\n",
    "    if not os.path.exists(local_path):\n",
    "        # try download once more if missing\n",
    "        try:\n",
    "            wav_bytes = supabase.storage.from_(BUCKET_NAME).download(object_path)\n",
    "            with open(local_path, \"wb\") as f:\n",
    "                f.write(wav_bytes)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    try:\n",
    "        sr, data = wavread(local_path)\n",
    "        if data.ndim > 1:\n",
    "            data = data[:,0]\n",
    "        ambient, chirp, _ = split_ambient_chirp(data, sample_rate=sr)\n",
    "        # Use rFFT and subtract magnitudes\n",
    "        spec_ambient = np.abs(np.fft.rfft(ambient))\n",
    "        spec_chirp = np.abs(np.fft.rfft(chirp))\n",
    "        spec_diff = np.clip(spec_chirp - spec_ambient, 0, None)\n",
    "        spec_log = np.log1p(spec_diff)\n",
    "        # Fix feature length to K_BINS\n",
    "        if len(spec_log) >= K_BINS:\n",
    "            feat = spec_log[:K_BINS]\n",
    "        else:\n",
    "            pad = np.zeros(K_BINS - len(spec_log))\n",
    "            feat = np.concatenate([spec_log, pad])\n",
    "        features.append(feat.astype(np.float32))\n",
    "        labels.append(row.get(\"material\"))\n",
    "        paths.append(local_path)\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "print(f\"Built {len(features)} samples with {K_BINS} features each\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df286cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough labeled samples to train a classifier.\n"
     ]
    }
   ],
   "source": [
    "# Train/test split and simple classifier\n",
    "if len(features) >= 2 and len(set(labels)) > 1:\n",
    "    X = np.vstack(features)\n",
    "    y = np.array(labels)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)\n",
    "\n",
    "    clf = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"logreg\", LogisticRegression(max_iter=200))\n",
    "    ])\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "else:\n",
    "    print(\"Not enough labeled samples to train a classifier.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f3762a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model not trained; skipping save.\n"
     ]
    }
   ],
   "source": [
    "# Save model if trained\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "models_dir = Path(\"models\")\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if 'clf' in globals() and len(features) >= 2 and len(set(labels)) > 1:\n",
    "    model_path = models_dir / \"material_classifier.pkl\"\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        pickle.dump(clf, f)\n",
    "    print(f\"Saved model to {model_path}\")\n",
    "else:\n",
    "    print(\"Model not trained; skipping save.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
